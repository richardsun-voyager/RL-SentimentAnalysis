{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "nlp = StanfordCoreNLP(r'../data/stanford-corenlp-full-2018-02-27', memory='8g',timeout=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'the food is nice but the staff was so horrible to us of all'\n",
    "#nlp.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nlp.parse(sentence)\n",
    "a\n",
    "nlp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tree import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Tree.fromstring(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ROOT                                                                      \n",
      "         |                                                                         \n",
      "         S                                                                        \n",
      "      ___|________                                                                 \n",
      "     |            VP                                                              \n",
      "     |         ___|________                                                        \n",
      "     |        |   |       SBAR                                                    \n",
      "     |        |   |     ___|_________                                              \n",
      "     |        |   |    |             S                                            \n",
      "     |        |   |    |         ____|________                                     \n",
      "     |        |   |    |        |             VP                                  \n",
      "     |        |   |    |        |          ___|____________                        \n",
      "     |        |   |    |        |         |               ADJP                    \n",
      "     |        |   |    |        |         |    ____________|________               \n",
      "     |        |   |    |        |         |   |     |               PP            \n",
      "     |        |   |    |        |         |   |     |       ________|___           \n",
      "     |        |   |    |        |         |   |     |      |            NP        \n",
      "     |        |   |    |        |         |   |     |      |     _______|___       \n",
      "     |        |   |    |        |         |   |     |      |    |           PP    \n",
      "     |        |   |    |        |         |   |     |      |    |        ___|___   \n",
      "     NP       |  ADJP  |        NP        |   |     |      |    NP      |       NP\n",
      "  ___|___     |   |    |    ____|____     |   |     |      |    |       |       |  \n",
      " DT      NN  VBZ  JJ   CC  DT        NN  VBD  RB    JJ     TO  PRP      IN      DT\n",
      " |       |    |   |    |   |         |    |   |     |      |    |       |       |  \n",
      "the     food  is nice but the      staff was  so horrible  to   us      of     all\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'wait', 'staff', 'is', 'very', 'friendly', ',', 'if', 'your', 'not', 'rude', 'or', 'picky', '...', '.']\n"
     ]
    }
   ],
   "source": [
    "print(b.leaves())\n",
    "words = ' '.join(b.leaves())\n",
    "#nlp.parse(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.load('data/models/parse_model_new2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "weight_hh_l0 = model.lstm.rnn.weight_hh_l0\n",
    "weight_hh_l0_reverse = model.lstm.rnn.weight_hh_l0_reverse\n",
    "weight_ih_l0 = model.lstm.rnn.weight_ih_l0\n",
    "weight_ih_l0_reverse = model.lstm.rnn.weight_ih_l0_reverse\n",
    "file = 'data/models/pretrained_lstm_params.pkl'\n",
    "with open(file, 'wb') as f:\n",
    "    pickle.dump([weight_hh_l0, weight_hh_l0_reverse, weight_ih_l0, weight_ih_l0_reverse], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.lstm.rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_hh_l0.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.lstm.rnn.weight_hh_l0.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b.leaf_treeposition(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 1, 0, 0, 0, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "print(b.leaf_treeposition(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 1, 0, 0, 0, 1, 0)\n"
     ]
    }
   ],
   "source": [
    "print(b.leaf_treeposition(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 1, 0, 0, 0, 2, 0)\n"
     ]
    }
   ],
   "source": [
    "print(b.leaf_treeposition(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 1, 0, 0, 0, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "print(b.leaf_treeposition(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = torch.LongTensor([0, 0, 1, 0, 0, 0])\n",
    "torch.nonzero(cc).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_node_distance(pos1, pos2):\n",
    "        '''\n",
    "        Compute the path for each node pair\n",
    "        Args:\n",
    "        pos1: a list, [0, 1, 0, 0]\n",
    "        pos2: a list, [0, 0, 1, 1, 0]\n",
    "        '''\n",
    "        if len(pos1) > len(pos2):\n",
    "            pos1, pos2 = pos2, pos1\n",
    "        distance = 0\n",
    "        for i, num in enumerate(pos1):\n",
    "            if num != pos2[i]:#The distance between two words\n",
    "                distance = np.abs(num-pos2[i]) + len(pos1)-1 + len(pos2)-1 - 2*i - 2\n",
    "                break\n",
    "        return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_node_distance((0, 3, 0, 0, 0), (0, 0, 0, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document: the taste is bad but the service is still nice!\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "# https://spacy.io/docs/usage/processing-text\n",
    "document = nlp(u\"the taste is bad but the service is still nice!\", parse=False)\n",
    "\n",
    "print('document: {0}'.format(document))\n",
    "\n",
    "# Load spacy's dependency tree into a networkx graph\n",
    "edges = []\n",
    "nodes = []\n",
    "for token in document:\n",
    "    # FYI https://spacy.io/docs/api/token\n",
    "    nodes.append(token.lower_+'-'+str(token.i))\n",
    "    for child in token.children:\n",
    "        edges.append(('{0}-{1}'.format(token.lower_,token.i),\n",
    "                      '{0}-{1}'.format(child.lower_,child.i)))\n",
    "\n",
    "graph = nx.Graph(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "node_num = len(nodes)\n",
    "mat = np.zeros([node_num, node_num])\n",
    "for i in np.arange(node_num-1):\n",
    "    for j in np.arange(i+1, node_num):\n",
    "        path_len = nx.shortest_path_length(graph, source=nodes[i], target=nodes[j])\n",
    "        #print(nodes[i], nodes[j], path_len)\n",
    "        mat[i, j] = path_len\n",
    "        mat[j, i] = path_len\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeView(('taste-1', 'the-0', 'is-2', 'bad-3', 'is-7', '!-10', 'but-4', 'service-6', 'the-5', 'still-8', 'nice-9'))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = list(graph.nodes())\n",
    "node_order = [int(node.split('-')[1]) for node in nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[nodes[i] for i in indice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 3., 2., 3., 4., 1., 0., 1., 2., 2., 3.])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8056868 , 0.95866547, 0.82866935, 0.80806435, 0.46183128,\n",
       "       0.96182307, 0.8547518 , 0.88206708, 0.79982468, 0.99671543])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.random.rand(5, 10)\n",
    "a.max(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.11089965e-02, 4.39369336e-02, 1.11089965e-02, 2.18749112e-03,\n",
       "       1.11089965e-02, 2.18749112e-03, 1.11089965e-02, 1.11089965e-02,\n",
       "       2.18749112e-03, 2.18749112e-03, 1.11089965e-02, 4.39369336e-02,\n",
       "       4.39369336e-02, 1.35335283e-01, 1.11089965e-02, 4.39369336e-02,\n",
       "       1.11089965e-02, 3.72665317e-06, 3.72665317e-06, 3.72665317e-06,\n",
       "       4.00652974e-05, 3.72665317e-06, 3.35462628e-04, 4.00652974e-05,\n",
       "       2.18749112e-03, 3.35462628e-04, 3.35462628e-04, 4.00652974e-05,\n",
       "       3.72665317e-06, 4.00652974e-05, 3.35462628e-04, 1.11089965e-02,\n",
       "       1.35335283e-01, 1.35335283e-01, 3.24652467e-01, 6.06530660e-01,\n",
       "       6.06530660e-01, 6.06530660e-01, 8.82496903e-01, 6.06530660e-01,\n",
       "       1.00000000e+00, 4.39369336e-02])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.exp(-(mat[-2,:])**2/max(mat[0,:]))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(nx.shortest_path_length(graph, source='soups-40', target='pinnacles-15'))\n",
    "# print(nx.shortest_path(graph, source='robots-0', target='awesomeness-11'))\n",
    "# print(nx.shortest_path(graph, source='robots-0', target='agency-15'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(nx.shortest_path_length(graph, source='pinnacles-15', target='soups-40'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeView(('oasis-1', 'an-0', 'of-2', ':-4', 'food-6', ',-7', 'uneven-10', 'refinement-3', '  -5', 'though-8', 'somewhat-9', 'reaches-13', ',-11', 'often-12', 'pinnacles-15', 'evident-34', '.-41', 'the-14', 'of-16', ')-31', 'passion-24', 'cuisine-20', 'new-17', 'american-18', 'fine-19', '   -21', 'chef-22', \"'s-23\", '(-25', 'and-26', 'execution-30', 'kitchen-27', \"'s-28\", 'precise-29', 'is-32', 'most-33', 'in-35', 'dishes-38', 'the-36', 'fish-37', 'and-39', 'soups-40'))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x15183c5090>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(3, 5, bidirectional=True)  # Input dim is 3, output dim is 3\n",
    "inputs = [torch.randn(1, 3) for _ in range(7)]  # make a sequence of length 5\n",
    "\n",
    "# initialize the hidden state.\n",
    "hidden = (torch.randn(2, 1, 5),\n",
    "          torch.randn(2, 1, 5))\n",
    "for i in inputs:\n",
    "    # Step through the sequence one element at a time.\n",
    "    # after each step, hidden contains the hidden state.\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2209,  0.1956, -0.1168, -0.2412,  0.0533,  0.0476,  0.0076,\n",
       "          -0.1719, -0.0568,  0.0475]]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.2209,  0.1956, -0.1168, -0.2412,  0.0533]],\n",
       " \n",
       "         [[ 0.0476,  0.0076, -0.1719, -0.0568,  0.0475]]]),\n",
       " tensor([[[ 0.4818,  0.6923, -0.2117, -0.6038,  0.1418]],\n",
       " \n",
       "         [[ 0.1372,  0.0135, -0.5880, -0.1042,  0.0840]]]))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "#from config import config\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Agent(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Agent in a reinforcement learning\n",
    "        '''\n",
    "        super(Agent, self).__init__()\n",
    "        self.a = 1\n",
    "        self.b = 2\n",
    "    \n",
    "    def print_word(self):\n",
    "        if self.train:\n",
    "            print(self.a)\n",
    "        else:\n",
    "            print(self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3.], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = torch.Tensor([1,2,3])\n",
    "p.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_ids = [1,2]\n",
    "p = [0.1, 0.9]\n",
    "action_id = np.random.choice(action_ids, p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "m = F.log_softmax\n",
    "loss = nn.NLLLoss()\n",
    "inputs = torch.randn(1, 5, requires_grad=True)\n",
    "target = torch.tensor([4])\n",
    "output = loss(m(inputs, 1), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.6089, -0.4229, -1.4677, -3.7077, -4.1180]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(inputs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.1180)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.Tensor([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [1,1,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delete_num = len(actions) - sum(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = torch.tensor(0.1, requires_grad=True)\n",
    "#delete_num = torch.FloatTensor(delete_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward = output + gamma * delete_num/len(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.randn(1,3)\n",
    "a\n",
    "a.argmax(1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2024, -0.3543, -1.9940]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method argmax in module torch.tensor:\n",
      "\n",
      "argmax(dim=None, keepdim=False) method of torch.Tensor instance\n",
      "    See :func:`torch.argmax`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(a.argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=10, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.randn(3, 3, 10)\n",
    "target = torch.randn(3, 3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "net = Net()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "b = net(a[0])\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(b, target[0]) + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.3285)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0979, -0.1896, -0.2080,  0.2035, -0.0114,  0.2057, -0.1765,\n",
       "          0.2613,  0.3052, -0.0388],\n",
       "        [ 0.1941, -0.1724, -0.1124,  0.2074, -0.3150,  0.0911,  0.1257,\n",
       "          0.2120, -0.3123,  0.3003],\n",
       "        [-0.0115, -0.0918,  0.0225,  0.1118,  0.0218,  0.1349,  0.2637,\n",
       "         -0.1661, -0.2237, -0.2150],\n",
       "        [-0.1060,  0.2870, -0.2603,  0.0518,  0.0776,  0.1443, -0.3030,\n",
       "         -0.1427,  0.3134,  0.0872],\n",
       "        [-0.0450, -0.0714,  0.2681, -0.0130,  0.0953,  0.0026, -0.0501,\n",
       "          0.0955, -0.0300, -0.1252]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "optimizer.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = 0\n",
    "for i in range(3):\n",
    "    b = net(a[i])\n",
    "    #target = target.view(1, -1)  # make it the same shape as output\n",
    "    criterion = nn.MSELoss()\n",
    "    loss = criterion(b, target[i]) + i\n",
    "    losses += loss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#loss.backward()\n",
    "optimizer.step() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "reward = np.random.rand(3,5)\n",
    "c = torch.from_numpy(reward).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(8, 4, \n",
    "              batch_first=True, num_layers= 1, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1, 5, 8)\n",
    "h = (torch.zeros(2, 1, 4), torch.zeros(2, 1, 4))\n",
    "output, h = rnn(a, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "hs = []\n",
    "for i in range(5):\n",
    "    output, h = rnn(a[0, i, :].view(1, 1, -1), h)\n",
    "    outputs.append(output)\n",
    "    hs.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[ 0.0624, -0.4514, -0.1991, -0.5642, -0.1650, -0.0613, -0.1559,\n",
       "           -0.1875]]]),\n",
       " tensor([[[ 0.0995, -0.0924, -0.2651, -0.2038, -0.2871, -0.0173,  0.0726,\n",
       "            0.1891]]]),\n",
       " tensor([[[ 0.3046, -0.1015, -0.3700, -0.1387,  0.0399, -0.1561, -0.0105,\n",
       "           -0.0555]]]),\n",
       " tensor([[[ 0.0424, -0.0791, -0.3042, -0.2253, -0.0614, -0.2343, -0.2259,\n",
       "           -0.0272]]]),\n",
       " tensor([[[-0.1314, -0.0866, -0.0825, -0.2587, -0.1092, -0.1347, -0.2015,\n",
       "            0.0827]]])]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from Agent import *\n",
    "from data_reader_general import *\n",
    "from config import config\n",
    "from Layer import GloveMaskCat\n",
    "import pickle\n",
    "import numpy as np\n",
    "import codecs\n",
    "import copy\n",
    "import os\n",
    "from torch import optim\n",
    "cat_layer = GloveMaskCat(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = data_reader(config)\n",
    "train_data = dr.load_data(config.data_path+'Restaurants_Train_v2.xml.pkl')\n",
    "test_data = dr.load_data(config.data_path+'Restaurants_Test_Gold.xml.pkl')\n",
    "dg_train = data_generator(config, train_data, False)\n",
    "dg_test =data_generator(config, test_data, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['We', 'saw', 'them', 'heating', 'up', 'at', 'least', 'one', 'frozen', 'item', 'though', 'I', \"'m\", 'not', 'sure', 'which', 'dim', 'sum', 'dish', 'it', 'was'], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0], 2, [43, 537, 170, 4262, 99, 30, 346, 69, 1604, 1048, 134, 9, 260, 22, 348, 78, 419, 420, 148, 16, 7], \"We saw them heating up at least one frozen item though I'm not sure which dim sum dish it was\"]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 3001\n",
      "Validating Samples: 601\n",
      "Testing Samples: 1120\n"
     ]
    }
   ],
   "source": [
    "dr = data_reader(config)\n",
    "train_data = dr.load_data(config.train_path)\n",
    "valid_data = dr.load_data(config.valid_path)\n",
    "test_data = dr.load_data(config.data_path+'Restaurants_Test_Gold.xml.pkl')\n",
    "print('Training Samples:', len(train_data))\n",
    "print('Validating Samples:', len(valid_data))\n",
    "print('Testing Samples:', len(test_data))\n",
    "\n",
    "dg_train = data_generator(config, train_data)\n",
    "dg_valid =data_generator(config, valid_data, False)\n",
    "dg_test =data_generator(config, test_data, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vecs, mask_vecs, label_list, sent_lens, tokens = next(dg_train.get_ids_samples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = mask_vecs[0]\n",
    "text = tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse_path import constituency_path, dependency_path\n",
    "dp = dependency_path()\n",
    "cp = constituency_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mask_index(masks):\n",
    "    '''\n",
    "    Find the indice of none zeros values in masks, namely the target indice\n",
    "    '''\n",
    "    target_indice = []\n",
    "    for mask in masks:\n",
    "        indice = torch.nonzero(mask == 1).squeeze(1).numpy()\n",
    "        target_indice.append(indice)\n",
    "    return target_indice\n",
    "\n",
    "def get_dependency_weight(tokens, targets, max_len):\n",
    "    '''\n",
    "    Dependency weight\n",
    "    tokens: texts\n",
    "    max_len: max length of texts\n",
    "    '''\n",
    "    weights = np.zeros([len(tokens), max_len])\n",
    "    for i, token in enumerate(tokens):\n",
    "        try:\n",
    "            graph = dp.build_graph(token)\n",
    "            mat = dp.compute_node_distance(graph, max_len)\n",
    "        except:\n",
    "            print('Error!!!!!!!!!!!!!!!!!!')\n",
    "            print(text)\n",
    "\n",
    "        try:\n",
    "            max_w, _, _ = dp.compute_soft_targets_weights(mat, targets[i])\n",
    "            weights[i, :len(max_w)] = max_w\n",
    "        except:\n",
    "            print('text process error')\n",
    "            print(text, targets[i])\n",
    "            break\n",
    "    return weights\n",
    "\n",
    "def get_context_weight(texts, targets, max_len):\n",
    "    '''\n",
    "    Constituency weight\n",
    "    '''\n",
    "    weights = np.zeros([len(texts), max_len])\n",
    "    for i, token in enumerate(texts):\n",
    "        #print('Original word num')\n",
    "        #print(len(token))\n",
    "        #text = ' '.join(token)#Connect them into a string\n",
    "        #stanford nlp cannot identify the abbreviations ending with '.' in the sentences\n",
    "\n",
    "        try:\n",
    "            max_w, min_w, a_v = cp.proceed(token, targets[i])\n",
    "            weights[i, :len(max_w)] = max_w\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(token, targets[i])\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"It is very overpriced\"\n",
    "# mask = torch.LongTensor([1,0,0,0,0,0,0,0,0])\n",
    "\n",
    "text = 'food is nice but the staff was so horrible to us'\n",
    "mask = torch.LongTensor([ 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_index = convert_mask_index([mask])\n",
    "a = get_context_weight([text], target_index, 20)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = get_dependency_weight([text], target_index, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_sent = cp.build_parser(text)\n",
    "positions = cp.get_leave_pos(parsed_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Tree('ROOT', [Tree('S', [Tree('NP', [Tree('PRP', ['It'])]), Tree('VP', [Tree('VBZ', ['is']), Tree('ADJP', [Tree('RB', ['very']), Tree('JJ', ['overpriced'])])])])])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 4, 4]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = cp.compute_target_distance(positions, 0)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.47236655, 0.36787944, 0.36787944])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-np.array(b)/len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = dp.build_graph(text)\n",
    "mat = dp.compute_node_distance(graph, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  3.,  2.,  3.,  4.,  3., 10., 10., 10., 10., 10., 10.,\n",
       "       10., 10.])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=mat[0]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.35335283e-01, 3.67879441e-01, 1.00000000e+00, 3.67879441e-01,\n",
       "       4.97870684e-02, 1.35335283e-01, 4.53999298e-05, 4.53999298e-05,\n",
       "       4.53999298e-05, 4.53999298e-05, 4.53999298e-05, 4.53999298e-05,\n",
       "       4.53999298e-05, 4.53999298e-05, 4.53999298e-05])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/IMDB/train.csv', header=None, names=['label', 'text'])\n",
    "test_data = pd.read_csv('data/IMDB/test.csv', header=None, names=['label', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>This is a extremely well-made film. The acting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Every once in a long while a movie will come a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>From the start, you know how this movie will e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "1      1  This is a extremely well-made film. The acting...\n",
       "2      0  Every once in a long while a movie will come a...\n",
       "5      0  From the start, you know how this movie will e..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iloc[[1,2,5], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_reader_imdb import dataHelper\n",
    "from config_parse import config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = dataHelper(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh.read_csv_data('data/IMDB/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, _ = dh.get_ids_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 600, 300])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dh.config.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_classification_models.cnn_classifier import CNNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNClassifier(300, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
